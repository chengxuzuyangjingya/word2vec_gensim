Auditory discrimination after left-hemisphere stroke: a mismatch negativity follow-up study.	We sought to determine the recovery of cortical auditory discrimination in aphasic, left-hemisphere-stroke patients by using an electrophysiological response called mismatch negativity (MMN) and speech-comprehension tests.
Functioning of olivocochlear bundle and speech perception in noise.	To evaluate the effect of contralateral acoustic stimuli on speech identification scores and to correlate this effect to contralateral suppression of evoked otoacoustic emission.
An investigation of list equivalency of the northwestern university auditory test no. 6 in interrupted broadband noise.	The equivalency of Lists 1 to 4 of the Northwestern University Auditory Test No. 6 (NU-6; T. W. Tillman and R. Carhart, 1966) was investigated in interrupted broadband noise. Forty-eight young adults with normal hearing participated. All lists were administered at 50 dB sensation level re: listener spondee recognition thresholds at signal-to-noise ratios (S/Ns) of 10, 5, 0, -5, -10, -15, -20, -25, and -30 dB. Significant differences in listener performance were observed only at S/Ns ranging from 10 to -10. Significant mean list differences varied from 5.8% to 12.0%. These findings support the notion that caution should be exercised in the interpretation of listener performance differences with NU-6 stimuli presented in a background of interrupted noise.
Recognition of distorted speech in children with and without learning problems.	The effects of listening to time-compressed speech alone and in a competing babble, with speech in and out of phase between ears, were studied in 10 children with no apparent auditory or learning problems and in 10 children with learning disabilities and a suspected central auditory processing problem. The children ranged in age from 8 to 10 years. Both groups showed significant decreases in speech recognition when speech was compressed at a rate of 60 percent as compared with recognition of normal-rate speech. However, the children in the learning disabilities group showed a greater decrease. Listening to time-compressed speech in a binaural mode resulted in better speech recognition than in a monaural mode for both groups. When speech was shifted 180 degrees out of phase between ears, both groups demonstrated a release from masking for speech presented at a fast rate (60% compression), but the normal group had a greater release from masking than the learning disabilities group. Also, the learning disabilities group did not show a release from masking for normal-rate speech (0% compression). When both groups listened to speech that had been compressed and presented in a babble, their performance supported a multiplicative distortion theory, with children in the learning disabilities group showing a slightly greater multiplicative effect than the children with no apparent problems. The results support the necessity of binaural hearing to maximize auditory performance in difficult listening situations in two populations of subjects.
Hearing two things at once: neurophysiological indices of speech segregation and identification.	The discrimination of concurrent sounds is paramount to speech perception. During social gatherings, listeners must extract information from a composite acoustic wave, which sums multiple individual voices that are simultaneously active. The observers' ability to identify two simultaneously presented vowels improves with increasing separation between the fundamental frequencies (f0) of the two vowels. Event-related potentials to stimuli presented during attend and ignore conditions revealed activity between 130 and 170 msec after sound onset that reflected the f0 differences between the two vowels. Another, more posterior and right-lateralized, negative wave maximal at 250 msec, and a central-parietal slow negativity were observed only during vowel identification and may index stimulus categorization. This sequence of neural events supports a multistage model of auditory scene analysis in which the spectral pattern of each vowel constituent is automatically extracted and then matched against representations of those vowels in working memory.
Prediction of hearing thresholds in children using an automated toy discrimination test.	A previous paper described the development of the prototype of a semi-automated, sensitive and accurate version of the McCormick Toy Discrimination Test. In this report we describe a further development of the hardware, and demonstrate that results obtained from the automated test provide a basis for estimating the mean elevation of pure-tone threshold in the child's better ear. The correlation between speech and pure-tone results is high. The average of the better ear pure-tone thresholds at 0.5, 1 and 4 kHz can be predicted from the word-discrimination threshold obtained with the toy test, with a 95% confidence interval of +/- 11 dB.
Can infants map meaning to newly segmented words? Statistical segmentation and word learning.	The present experiments investigated how the process of statistically segmenting words from fluent speech is linked to the process of mapping meanings to words. Seventeen-month-old infants first participated in a statistical word segmentation task, which was immediately followed by an object-label-learning task. Infants presented with labels that were words in the fluent speech used in the segmentation task were able to learn the object labels. However, infants presented with labels consisting of novel syllable sequences (nonwords; Experiment 1) or familiar sequences with low internal probabilities (part-words; Experiment 2) did not learn the labels. Thus, prior segmentation opportunities, but not mere frequency of exposure, facilitated infants' learning of object labels. This work provides the first demonstration that exposure to word forms in a statistical word segmentation task facilitates subsequent word learning.
The effects of background noise on dichotic listening to consonant-vowel syllables.	Lateralization of verbal processing is frequently studied with the dichotic listening technique, yielding a so called right ear advantage (REA) to consonant-vowel (CV) syllables. However, little is known about how background noise affects the REA. To address this issue, we presented CV-syllables either in silence or with traffic background noise vs. 'babble'. Both 'babble' and traffic noise resulted in a smaller REA compared to the silent condition. The traffic noise, moreover, had a significantly greater negative effect on the REA than the 'babble', caused both by a decreased right ear response as well as an increased left ear response. The results are discussed in terms of alertness and attentional factors.
Comparison of objective and subjective measures of speech intelligibility in elderly hearing-impaired listeners.	Three experiments were performed to evaluate the use of subjective intelligibility estimations as a method for measuring hearing aid benefit. Subjective and objective speech intelligibility scores were compared for young normal-hearing and elderly hearing-impaired listeners. Objective intelligibility scores were obtained using the Connected Speech Test (CST). This test consists of conversationally produced passages of speech that the listener repeats sentence by sentence. To provide subjective intelligibility scores, listeners estimated the percentage that they understood of each CST passage. Comparison of the two types of scores revealed that they were closely related in both groups of subjects (r = .82-.92). Although the two types of scores were essentially equal for normal-hearing subjects, the hearing-impaired listeners tended to produce subjective estimations of intelligibility that were significantly lower than their objective scores. Manipulation of visual cues and amplification, in an attempt to influence the hearing-impaired listeners' expectation of understanding speech, had no effect on the subjective-objective score differential. The difference between subjective and objective scores in the hearing-impaired group was not related to audiometric variables such as speech reception threshold, audiogram, or duration of hearing loss. It was concluded that comparative hearing aid evaluations using subjective intelligibility estimates would usually produce the same relative outcome as evaluations using the objective intelligibility measurement procedure. However, scores obtained with the objective procedure had smaller critical differences. Thus, when both types of scores are based on the same number of passages, the objective measurement procedure would be the more sensitive to differences among hearing aids.
The CHAPS, SIFTER, and TAPS-R as predictors of (C)AP skills and (C)APD.	In this study, the authors investigated the relationships between 3 tests used to screen for (central) auditory processing disorder ([C]APD)--the Children's Auditory Performance Scale (CHAPS; W. J. Smoski, M. A. Brunt, & J. C. Tannahill, 1998), the Screening Instrument for Targeting Educational Risk (SIFTER; K. Anderson, 1989), and the Test of Auditory Perceptual Skills--Revised (TAPS-R; M. Y. Gardner, 1997)-and 4 tests used to diagnostically assess for (C)APD: Low-Pass Filtered Speech (LPFS), Competing Sentences (CS), Two-Pair Dichotic Digits (DD), and Frequency Patterns With Linguistic Report (FP).
Effects of aging and noise on real-time spoken word recognition: evidence from eye movements.	To use eye tracking to investigate age differences in real-time lexical processing in quiet and in noise in light of the fact that older adults find it more difficult than younger adults to understand conversations in noisy situations.
The relationship between brainstem temporal processing and performance on tests of central auditory function in children with reading disorders.	Studies using speech stimuli to elicit electrophysiologic responses have found approximately 30% of children with language-based learning problems demonstrate abnormal brainstem timing. Research is needed regarding how these responses relate to performance on behavioral tests of central auditory function. The purpose of the study was to investigate performance of children with dyslexia with and without abnormal brainstem timing and children with no history of learning or related disorders on behavioral tests of central auditory function.
Predicting the intelligibility of vocoded speech.	The purpose of this study is to evaluate the performance of a number of speech intelligibility indices in terms of predicting the intelligibility of vocoded speech.
Bilateral bone conduction devices: improved hearing ability in children with bilateral conductive hearing loss.	The aim of the study was to investigate whether children with bilateral conductive hearing loss benefit from their second device (i.e., the bilateral bone conduction device [BCD]).
Word recognition skills of children and adults in background noise.	This study compared the word recognition performance of 4 to 6 year old children and adults on the Word Intelligibility by Picture Identification (WIPI) Test presented via sound field in quiet and in a background of multitalker noise and pink noise. Although the adults had no difficulty recognizing speech in all situations, the children performed significantly poorer in both noise conditions. Furthermore, the multitalker noise proved to be more adverse than the pink noise on speech discrimination.
Pre-implant evaluation of speech and hearing.	This paper describes an approach taken to predict, in advance of invasive surgery, whether a permanent cochlear prosthesis will serve as an aid to hearing in postlingually deaf adults. Nine subjects were implanted transtympanically with a temporary single-channel round window electrode. Over the course of one week a number of tests were conducted, including (1) the measurement of current thresholds over a range of frequencies for sine, square and biphasic pulse waveforms and minimum detectable gap between a pair of short bursts; (2) the discrimination of elementary speech features of live voice such as interruption, intonation, and stress placement; (3) the recognition of consonants, and (4) speech tracking. Eight subjects were able to appreciate changes in loudness, pitch, duration and temporal gap for frequencies below 1 kHz. All showed significant improvements over listening with high-power hearing aids in discriminating a variety of changes in elementary speech features. It was found that the recognition of consonants and speech tracking was heavily dependent on lipreading.
On prediction of hearing disability.	The present investigation was performed in order to evaluate the pure-tone frequency and/or averages of frequencies best correlated with speech intelligibility measured by the discrimination score (DS) in quiet and in background noise, and, in addition, indicate a valid low fence of the DS when correlated to a self-assessment procedure. The material comprises 158 male subjects with a median age of 60 years, range 52-72 years, drawn from an ongoing longitudinal epidemiological investigation. By self-assessment 36% indicated hearing disability in noisy backgrounds, while 64% had no hearing problems. The pure-tone frequency that correlated best with the speech intelligibility in quiet was the 2-kHz pure-tone frequency. In background noise the best correlation was found with the 3-kHz pure-tone frequency. In the group of subjects with complaints of hearing problems, the median discrimination score in background noise was 84% (IQR 72-92), while in the group of subjects with no complaints the median discrimination score in noise was 92% (IQR 88-96). Based on the results it is concluded that DS in background noise is a valuable measure in the assessment of hearing disability, but no low fence value can be indicated on the basis of the present results.
Speech recognition for 40 patients receiving multichannel cochlear implants.	We collected data on 40 patients who received the Nucleus multichannel cochlear implant. Results were reviewed to determine if the coding strategy is effective in transmitting the intended speech features and to assess patient benefit in terms of communication skills. All patients demonstrated significant improvement over preoperative results with a hearing aid for both lipreading enhancement and speech recognition without lipreading. Of the patients, 50% demonstrated ability to understand connected discourse with auditory input only. For the 23 patients who were tested 12 months postoperatively, there was substantial improvement in open-set speech recognition.
Long-term average spectrography of speech. Discrimination between the normal voice and the pathological voice]	LTAS (Long Time Average Spectra) were used for discrimination between a sample of 30 normal voices and a sample of 30 pathological voices. A highly significant difference could be observed. There is also a good correlation between the degree of hoarseness as evaluated by LTAS and the sonographic classification of Yanagihara. A possible application for automatic recognition of voice pathology is evoked.
An evaluation of speech audiometry by bone conduction in hearing-impaired adults.	Pure-tone thresholds, speech reception thresholds (SRT), and speech discrimination scores (DS) were obtained by ac and bc on 20 normal-hearing and 30 hearing-impaired adults. Correlations between the SRT and pure-tone thresholds (ave. of .5, 1, and 2 kc/s) were significant by both ac and bc. Correlations between DS by ac and bc were also highly significant, indicating the value of the bc DS in specific difficult cases. The clinical observation was confirmed statistically of decreasing DS with increasing sensorineural hearing loss.
A comparison of half- vs full-list speech discrimination scores in a hearing-impaired geriatric population.	Speech discrimination testing using a recorded List A of the CID W-22 test was completed on 76 elderly persons with varying degrees of sensorineural hearing impairment. Half- and full-list scores were compared and the statistical analysis provided support for half-list testing with this population. Variability in scores was discussed relative to expected variation based on previous data by Thornton and Raffin (1978). Recommendations were made concerning alternatives to the presentation of the entire 50-item list.
Perception of synthetic speech sounds by hearing-impaired listeners.	Volunteers (7 men, 8 women) with mild to severe hearing losses listened by monaural earphone to 5 series of computer-synthesized speech syllables, and identified each token. Presentation level 30 db SL. The 5 series consisted of (a, b) steady-state vowels varying from to [o] and from [o] to [a], (c,d) CV syllables varying from [ba] to [wa], and from [da] to [ya], differing in the rate of formant transitions at onset, and (e) CV syllables varying from [ba] to [da] differing in both direction and extent of formant transitions from locus to vowel. All hearing-impaired Ss categorized the vowels essentially the same as normal control Ss; some had difficulty identifying the stop vs glide series, and all but 2 were unable to identify the [b-d] series normally. A few impaired Ss improved at a presentation level close to tolerable limits. Results imply a "hierarchy of difficulty" based on the nature of the spectral cue in different speech sound types.
Evaluation of a new tape recording of the synthetic sentence identification test.	The purpose of this study was to collect normative data on a commercially available tape recording of the Synthetic Sentence Identification test with ipsilateral competing message. Twenty normal-hearing subjects with no history of central auditory dysfunction were used. Mean percentage of intelligibility scores and standard deviations were obtained at various message-competition ratios. Results were compared to previous research. The data obtained using this recording can now be used as a reference for making clinical judgments.
Lateralization characteristics in the perception of speech in noise by children of different age groups]	The comparative investigation in ontogenesis of the noise immunity of child sensorial perception of two kinds of bioacoustical information (the emotional one being more evolutionary old and the semantic one being evolutionary younger) has shown that the perception effectiveness of these kinds of information depends on the noise level, the age of a child and the kind of information. The perception of semantic information is not provided with the reliable mechanisms of signal identification from noise even to the age of 16 while such mechanisms for perception of emotional information are formed in ontogenesis by the age of 14 and they are associated with the activity of the right hemisphere.
The role of amplitude modulation in forming the auditory images of speech signals]	The identification of stationary vowels in influenced by the change in relations of formant amplitudes as if their "centre gravity" is used in phoneme decision. That is valid for formants spaced in critical frequency band equal approximately 3.5 Bark. The hypothesis about large-scale spectral integration in auditory system is based on this effect. The data obtained supports the hypothesis in respect to non-stationary sounds, too. Imitation of the large-scale spectral integration on the model of auditory processing suggests that the frequency band of the integration may be equal to 3.5 Bark.
Time compression and release from masking in adults and children.	We studied the effect of speech time compression (TC), alone and in the presence of competing babble, in 24 adults and 24 children. Both adults and children showed significant decreases in speech recognition when speech was compressed at a rate of 60 percent, as compared with recognition of normal-rate speech. Listening to time-compressed speech in a binaural homophasic mode resulted in better speech recognition than in a monaural mode for both adults and children. When speech was antiphasic, both adults and children demonstrated a release from masking for normal-rate (0% compression) and 60 percent time-compressed speech. When both groups listened to speech that had been compressed and presented in a babble, their performance supported a multiplicative distortion theory. The results support the importance of binaural hearing for optimizing auditory performance in difficult listening situations.
Physical diagnostic procedures: whispered speech and tuning fork test]	Hearing impairment occurs in 10% of the Dutch population and may lead to major communication problems and even social isolation. A good method to detect hearing loss in a general practice is the screening audiometer. The treating physician may further use the whispered speech test and tuning fork tests which together give a good impression of the severity and the nature of the hearing loss if any. The whispered speech test is best performed in the standardized form according to the guideline 'Slechthorendheid' [hardness of hearing] of the Dutch College of General Practitioners (NHG), in which certain combinations of letters are recommended. The tuning fork tests according to Rinne and Weber indicate a difference in perception and conduction deafness, and are decisive for any hearing asymmetry. Use of the whispered speech test and of the tuning fork tests is recommended for adults and children from the age of 7.
