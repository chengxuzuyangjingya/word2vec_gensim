A knowledge-based search engine to navigate the information thicket of nanotoxicology.	The risk assessment of nano-sized materials (NM) currently suffers from great uncertainties regarding their putative toxicity for humans and the environment. An extensive amount of the respective original research literature has to be evaluated before a targeted and hypothesis-driven Environmental and Health Safety research can be stipulated. Furthermore, to comply with the European animal protection legislation in vitro testing has to be preferred whenever possible. Against this background, there is the need for tools that enable producers of NM and risk assessors for a fast and comprehensive data retrieval, thereby linking the 3Rs principle to the hazard identification of NM. Here we report on the development of a knowledge-based search engine that is tailored to the particular needs of risk assessors in the area of NM. Comprehensive retrieval of data from studies utilising in vitro as well as in vivo methods relying on the PubMed database is presented exemplarily with a titanium dioxide case study. A fast, relevant and reliable information retrieval is of paramount importance for the scientific community dedicated to develop safe NM in various product areas, and for risk assessors obliged to identify data gaps, to define additional data requirements for approval of NM and to create strategies for integrated testing using alternative methods.
Gastric cancer-related information on the Internet: incomplete, poorly accessible, and overly commercial.	Patients increasingly use the Internet for gastric cancer information. However, the quality of the information is questionable. We evaluated the accuracy, completeness, accessibility, reliability, and readability of gastric cancer websites.
Quality of eating disorders websites: what adolescents and their families need to know.	  The purpose of this study was to examine the accessibility and content quality of eating disorder websites.
Allie: a database and a search service of abbreviations and long forms.	Many abbreviations are used in the literature especially in the life sciences, and polysemous abbreviations appear frequently, making it difficult to read and understand scientific papers that are outside of a reader's expertise. Thus, we have developed Allie, a database and a search service of abbreviations and their long forms (a.k.a. full forms or definitions). Allie searches for abbreviations and their corresponding long forms in a database that we have generated based on all titles and abstracts in MEDLINE. When a user query matches an abbreviation, Allie returns all potential long forms of the query along with their bibliographic data (i.e. title and publication year). In addition, for each candidate, co-occurring abbreviations and a research field in which it frequently appears in the MEDLINE data are displayed. This function helps users learn about the context in which an abbreviation appears. To deal with synonymous long forms, we use a dictionary called GENA that contains domain-specific terms such as gene, protein or disease names along with their synonymic information. Conceptually identical domain-specific terms are regarded as one term, and then conceptually identical abbreviation-long form pairs are grouped taking into account their appearance in MEDLINE. To keep up with new abbreviations that are continuously introduced, Allie has an automatic update system. In addition, the database of abbreviations and their long forms with their corresponding PubMed IDs is constructed and updated weekly. Database URL: The Allie service is available at http://allie.dbcls.jp/.
Social media networking: YouTube and search engine optimization.	This is the third part of a three-part article on social media networking. This installment will focus on YouTube and search engine optimization. This article will explore the application of YouTube to the medical practice and how YouTube can help a practice retain its existing patients and attract new patients to the practice. The article will also describe the importance of search engine optimization and how to make your content appear on the first page of the search engines such as Google, Yahoo, and YouTube.
Ensembl BioMarts: a hub for data retrieval across taxonomic space.	For a number of years the BioMart data warehousing system has proven to be a valuable resource for scientists seeking a fast and versatile means of accessing the growing volume of genomic data provided by the Ensembl project. The launch of the Ensembl Genomes project in 2009 complemented the Ensembl project by utilizing the same visualization, interactive and programming tools to provide users with a means for accessing genome data from a further five domains: protists, bacteria, metazoa, plants and fungi. The Ensembl and Ensembl Genomes BioMarts provide a point of access to the high-quality gene annotation, variation data, functional and regulatory annotation and evolutionary relationships from genomes spanning the taxonomic space. This article aims to give a comprehensive overview of the Ensembl and Ensembl Genomes BioMarts as well as some useful examples and a description of current data content and future objectives. Database URLs: http://www.ensembl.org/biomart/martview/; http://metazoa.ensembl.org/biomart/martview/; http://plants.ensembl.org/biomart/martview/; http://protists.ensembl.org/biomart/martview/; http://fungi.ensembl.org/biomart/martview/; http://bacteria.ensembl.org/biomart/martview/.
The InterPro BioMart: federated query and web service access to the InterPro Resource.	The InterPro BioMart provides users with query-optimized access to predictions of family classification, protein domains and functional sites, based on a broad spectrum of integrated computational models ('signatures') that are generated by the InterPro member databases: Gene3D, HAMAP, PANTHER, Pfam, PIRSF, PRINTS, ProDom, PROSITE, SMART, SUPERFAMILY and TIGRFAMs. These predictions are provided for all protein sequences from both the UniProt Knowledge Base and the UniParc protein sequence archive. The InterPro BioMart is supplementary to the primary InterPro web interface (http://www.ebi.ac.uk/interpro), providing a web service and the ability to build complex, custom queries that can efficiently return thousands of rows of data in a variety of formats. This article describes the information available from the InterPro BioMart and illustrates its utility with examples of how to build queries that return useful biological information. Database URL: http://www.ebi.ac.uk/interpro/biomart/martview.
Educating the patient: challenges and opportunities with current technology.	Patients using the Internet are inundated with abundant information on health care that may be correct and may be incorrect. It is becoming the role of clinicians to enable patients to educate themselves by providing information about accurate and reliable Web sites, and to answer questions from literature that patients encounter. In addition, there is a myriad of technological advances to help patients and clinicians access, retrieve, and file information, and numerous communication tools to foster the patient-clinician dialog. This article provides an overview and some recommendations for clinicians to help patients better use information to achieve better outcomes.
Staying current by searching the veterinary literature.	The body of knowledge in veterinary medicine and the biomedical sciences continues to grow logarithmically, and learning about new developments in veterinary medicine requires successful navigation of recently published literature worldwide. This article examines how veterinarians can use different types of automated services from databases and publishers to search the current and past literature, access articles, and manage references that are found.
Is there a valid app for that? Validity of a free pedometer iPhone application.	This study examined the validity of a selected free pedometer application (iPedometer; IP) for the iPhone that could be used to assess physical activity.
Google walkability: a new tool for local planning and public health research?	We investigate the association of different composite walkability measures with individual walking behaviors to determine if multicomponent metrics of walkability are more useful for assessing the health impacts of the built environment than single component measures.
PPISEARCHENGINE: gene ontology-based search for protein-protein interactions.	This paper presents a new search engine called PPISearchEngine which finds protein-protein interactions (PPIs) using the gene ontology (GO) and the biological relations of proteins. For efficient retrieval of PPIs, each GO term is assigned a prime number and the relation between the terms is represented by the product of prime numbers. This representation is hidden from users but facilitates the search for the interactions of a query protein by unique prime factorisation of the number that represents the query protein. For a query protein, PPISearchEngine considers not only the GO term associated with the query protein but also the GO terms at the lower level than the GO term in the GO hierarchy, and finds all the interactions of the query protein which satisfy the search condition. In contrast, the standard keyword-matching or ID-matching search method cannot find the interactions of a protein unless the interactions involve a protein with explicit annotations. To the best of our knowledge, this search engine is the first method that can process queries like 'for protein p with GO [Formula: see text], find p's interaction partners with GO [Formula: see text]'. PPISearchEngine is freely available to academics at http://search.hpid.org/.
Curating the world's peer-reviewed literature.	New technologies are transforming academic publishing, including surgical research. The author considers a variety of the new systems, platforms and search engines that are fuelling this information revolution, as well as the bibliometrics and citation analysis necessary for filtering  quality material for the increasingly inundated researcher.
A comparison of two search methods for determining the scope of systematic reviews and health technology assessments.	This study aims to compare two different search methods for determining the scope of a requested systematic review or health technology assessment. The first method (called the Direct Search Method) included performing direct searches in the Cochrane Database of Systematic Reviews (CDSR), Database of Abstracts of Reviews of Effects (DARE) and the Health Technology Assessments (HTA). Using the comparison method (called the NHS Search Engine) we performed searches by means of the search engine of the British National Health Service, NHS Evidence.
Revisit on the evolutionary relationship between alternative splicing and gene duplication.	Gene duplications and alternative splicing (AS) isoforms are two widespread types of genetic variations that can facilitate diversification of protein function. A number of studies claimed that after gene duplication, two AS isoforms with differential functions can be 'fixed', respectively, in each of the duplicate copies. This simple 'functional-sharing' hypothesis was recently challenged by Roux and Robinson-Rechavi (2011). Instead, they proposed a more sophisticated hypothesis, invoking that less alternative splicing genes tend to be duplicated more frequently, and single-copy genes are younger than duplicate genes, or the 'duplicability-age' hypothesis for short. In this letter, we show that all these genome-wide analyses of AS isoforms actually did not provide clear-cut evidence to nullify the basic idea of functional-sharing hypothesis. After updating our understanding of genome-wide alternative splicing, duplicability and CNV (copy number variation), we argue that the foundation of the duplicability-age hypothesis remains to be justified carefully. Finally, we suggest that a better approach to resolving this controversy is the correspondence analysis of indels (insertions and deletions) between duplicate genes to the genomic exon-intron structure, which can be used to experimentally test the effect of functional-sharing hypothesis.
Computing posterior probabilities for score-based alignments using ppALIGN.	Score-based pairwise alignments are widely used in         bioinformatics in particular with molecular database search         tools, such as the BLAST family.  Due to sophisticated heuristics,         such algorithms are usually fast but  the         underlying scoring model unfortunately lacks a statistical description of         the reliability of the reported alignments.  In particular,         close to gaps, in low-score or low-complexity         regions, a huge number of alternative alignments arise which         results in a decrease of the certainty of the alignment.          ppALIGN is a software package that uses hidden Markov         Model techniques to compute position-wise reliability of          score-based pairwise alignments of DNA or protein sequences.  The         design of the model allows for a direct connection between the         scoring function and the parameters of the probabilistic         model. For this reason it is suitable to analyze the         outcomes of popular score based aligners and search tools         without having to choose a complicated set of parameters. By contrast, our program         only requires the classical score parameters (the scoring function         and gap costs). The package comes along with a library written         in C++, a standalone program for user defined         alignments (ppALIGN) and another program (ppBLAST)          which can process a complete result set of BLAST.  The main algorithms         essentially exhibit a linear time complexity (in the alignment         lengths), and they are hence suitable for on-line computations.         We have also included alternative decoding algorithms to provide         alternative alignments.                 ppALIGN is a fast         program/library that helps detect and quantify questionable         regions in pairwise alignments.  Due to its structure, the         input/output interface it can to be            connected to other post-processing tools.  Empirically, we illustrate its         usefulness in terms of correctly predicted reliable regions         for sequences generated using the ROSE model for sequence         evolution, and identify sensor-specific         regions in the denitrifying betaproteobacterium         Aromatoleum aromaticum.
Access and use of the GUDMAP database of genitourinary development.	The Genitourinary Development Molecular Atlas Project (GUDMAP) aims to document gene expression across time and space in the developing urogenital system of the mouse, and to provide access to a variety of relevant practical and educational resources. Data come from microarray gene expression profiling (from laser-dissected and FACS-sorted samples) and in situ hybridization at both low (whole-mount) and high (section) resolutions. Data are annotated to a published, high-resolution anatomical ontology and can be accessed using a variety of search interfaces. Here, we explain how to run typical queries on the database, by gene or anatomical location, how to view data, how to perform complex queries, and how to submit data.
Easy guide to searching for evidence for the busy clinician.	The busy clinician is constantly faced with clinical questions regarding patient care. It is easy to feel overwhelmed by the large amount of health information available electronically. This article offers one easy approach for searching the electronic database. It is intended for the busy clinician who is unsure how to conduct an electronic search. It provides guidance on where to search and how to search using the PICO search method. It also provides a list of useful resources to help clinicians critically appraise the articles found to determine its relevance.
Cloud CPFP: a shotgun proteomics data analysis pipeline using cloud and high performance computing.	We have extended the functionality of the Central Proteomics Facilities Pipeline (CPFP) to allow use of remote cloud and high performance computing (HPC) resources for shotgun proteomics data processing. CPFP has been modified to include modular local and remote scheduling for data processing jobs. The pipeline can now be run on a single PC or server, a local cluster, a remote HPC cluster, and/or the Amazon Web Services (AWS) cloud. We provide public images that allow easy deployment of CPFP in its entirety in the AWS cloud. This significantly reduces the effort necessary to use the software, and allows proteomics laboratories to pay for compute time ad hoc, rather than obtaining and maintaining expensive local server clusters. Alternatively the Amazon cloud can be used to increase the throughput of a local installation of CPFP as necessary. We demonstrate that cloud CPFP allows users to process data at higher speed than local installations but with similar cost and lower staff requirements. In addition to the computational improvements, the web interface to CPFP is simplified, and other functionalities are enhanced. The software is under active development at two leading institutions and continues to be released under an open-source license at http://cpfp.sourceforge.net.
Automated phosphopeptide identification using multiple MS/MS fragmentation modes.	Phosphopeptide identification is still a challenging task because fragmentation spectra obtained by mass spectrometry do not necessarily contain sufficient fragment ions to establish with certainty the underlying amino acid sequence and the precise phosphosite. To improve upon this, it has been suggested to acquire pairs of spectra from every phosphorylated precursor ion using different fragmentation modes, for example CID, ETD, and/or HCD. The development of automated tools for the interpretation of these paired spectra has however, until now, lagged behind. Using phosphopeptide samples analyzed by an LTQ-Orbitrap instrument, we here assess an approach in which, on each selected precursor, a pair of CID spectra, with or without multistage activation (MSA or MS2, respectively), are acquired in the linear ion trap. We applied this approach on phosphopeptide samples of variable proteomic complexity obtained from Arabidopsis thaliana . We present a straightforward computational approach to reconcile sequence and phosphosite identifications provided by the database search engine Mascot on the spectrum pairs, using two simple filtering rules, at the amino acid sequence and phosphosite localization levels. If multiple sequences and/or phosphosites are likely, they are reported in the consensus sequence. Using our program FragMixer, we could assess that on samples of moderate complexity, it was worth combining the two fragmentation schemes on every precursor ion to help efficiently identify amino acid sequences and precisely localize phosphosites. FragMixer can be flexibly configured, independently of the Mascot search parameters, and can be applied to various spectrum pairs, such as MSA/ETD and ETD/HCD, to automatically compare and combine the information provided by these more differing fragmentation modes. The software is openly accessible and can be downloaded from our Web site at http://proteomics.fr/FragMixer.
What do patients know about their low back pain? An analysis of the quality of information available on the Internet.	Previous surveys showed a poor quality of the web sites providing health information about low back pain. However, the rapid and continuous evolution of the Internet content may question the current validity of those investigations. The present study is aimed to quantitatively assess the quality of the Internet information about low back pain retrieved with the most commonly employed search engines. An Internet search with the keywords "low back pain" has been performed with Google, Yahoo!® and Bing™ in the English language. The top 30 hits obtained with each search engine were evaluated by five independent raters and averaged following criteria derived from previous works. All search results were categorized as declaring compliant to a quality standard for health information (e.g. HONCode) or not and based on the web site type (Institutional, Free informative, Commercial, News, Social Network, Unknown). The quality of the hits retrieved by the three search engines was extremely similar. The web sites had a clear purpose, were easy to navigate, and mostly lacked in validity and quality of the provided links. The conformity to a quality standard was correlated with a marked greater quality of the web sites in all respects. Institutional web sites had the best validity and ease of use. Free informative web sites had good quality but a markedly lower validity compared to Institutional websites. Commercial web sites provided more biased information. News web sites were well designed and easy to use, but lacked in validity. The average quality of the hits retrieved by the most commonly employed search engines could be defined as satisfactory and favorably comparable with previous investigations. Awareness of the user about checking the quality of the information remains of concern.
Learning from decoys to improve the sensitivity and specificity of proteomics database search results.	The statistical validation of database search results is a complex issue in bottom-up proteomics. The correct and incorrect peptide spectrum match (PSM) scores overlap significantly, making an accurate assessment of true peptide matches challenging. Since the complete separation between the true and false hits is practically never achieved, there is need for better methods and rescoring algorithms to improve upon the primary database search results. Here we describe the calibration and False Discovery Rate (FDR) estimation of database search scores through a dynamic FDR calculation method, FlexiFDR, which increases both the sensitivity and specificity of search results. Modelling a simple linear regression on the decoy hits for different charge states, the method maximized the number of true positives and reduced the number of false negatives in several standard datasets of varying complexity (18-mix, 49-mix, 200-mix) and few complex datasets (E. coli and Yeast) obtained from a wide variety of MS platforms. The net positive gain for correct spectral and peptide identifications was up to 14.81% and 6.2% respectively. The approach is applicable to different search methodologies--separate as well as concatenated database search, high mass accuracy, and semi-tryptic and modification searches. FlexiFDR was also applied to Mascot results and showed better performance than before. We have shown that appropriate threshold learnt from decoys, can be very effective in improving the database search results. FlexiFDR adapts itself to different instruments, data types and MS platforms. It learns from the decoy hits and sets a flexible threshold that automatically aligns itself to the underlying variables of data quality and size.
Virus pathogen database and analysis resource (ViPR): a comprehensive bioinformatics database and analysis resource for the coronavirus research community.	Several viruses within the Coronaviridae family have been categorized as either emerging or re-emerging human pathogens, with Severe Acute Respiratory Syndrome Coronavirus (SARS-CoV) being the most well known. The NIAID-sponsored Virus Pathogen Database and Analysis Resource (ViPR, www.viprbrc.org) supports bioinformatics workflows for a broad range of human virus pathogens and other related viruses, including the entire Coronaviridae family. ViPR provides access to sequence records, gene and protein annotations, immune epitopes, 3D structures, host factor data, and other data types through an intuitive web-based search interface. Records returned from these queries can then be subjected to web-based analyses including: multiple sequence alignment, phylogenetic inference, sequence variation determination, BLAST comparison, and metadata-driven comparative genomics statistical analysis. Additional tools exist to display multiple sequence alignments, view phylogenetic trees, visualize 3D protein structures, transfer existing reference genome annotations to new genomes, and store or share results from any search or analysis within personal private 'Workbench' spaces for future access. All of the data and integrated analysis and visualization tools in ViPR are made available without charge as a service to the Coronaviridae research community to facilitate the research and development of diagnostics, prophylactics, vaccines and therapeutics against these human pathogens.
Method for tracking core-contributed publications.	Accurately tracking core-contributed publications is an important and often difficult task. Many core laboratories are supported by programmatic grants (such as Cancer Center Support Grant and Clinical Translational Science Awards) or generate data with instruments funded through S10, Major Research Instrumentation, or other granting mechanisms. Core laboratories provide their research communities with state-of-the-art instrumentation and expertise, elevating research. It is crucial to demonstrate the specific projects that have benefited from core services and expertise. We discuss here the method we developed for tracking core contributed publications.
Wiki-pi: a web-server of annotated human protein-protein interactions to aid in discovery of protein function.	Protein-protein interactions (PPIs) are the basis of biological functions. Knowledge of the interactions of a protein can help understand its molecular function and its association with different biological processes and pathways. Several publicly available databases provide comprehensive information about individual proteins, such as their sequence, structure, and function. There also exist databases that are built exclusively to provide PPIs by curating them from published literature. The information provided in these web resources is protein-centric, and not PPI-centric. The PPIs are typically provided as lists of interactions of a given gene with links to interacting partners; they do not present a comprehensive view of the nature of both the proteins involved in the interactions. A web database that allows search and retrieval based on biomedical characteristics of PPIs is lacking, and is needed. We present Wiki-Pi (read Wiki-π), a web-based interface to a database of human PPIs, which allows users to retrieve interactions by their biomedical attributes such as their association to diseases, pathways, drugs and biological functions. Each retrieved PPI is shown with annotations of both of the participant proteins side-by-side, creating a basis to hypothesize the biological function facilitated by the interaction. Conceptually, it is a search engine for PPIs analogous to PubMed for scientific literature. Its usefulness in generating novel scientific hypotheses is demonstrated through the study of IGSF21, a little-known gene that was recently identified to be associated with diabetic retinopathy. Using Wiki-Pi, we infer that its association to diabetic retinopathy may be mediated through its interactions with the genes HSPB1, KRAS, TMSB4X and DGKD, and that it may be involved in cellular response to external stimuli, cytoskeletal organization and regulation of molecular activity. The website also provides a wiki-like capability allowing users to describe or discuss an interaction. Wiki-Pi is available publicly and freely at http://severus.dbmi.pitt.edu/wiki-pi/.
Building an efficient curation workflow for the Arabidopsis literature corpus.	TAIR (The Arabidopsis Information Resource) is the model organism database (MOD) for Arabidopsis thaliana, a model plant with a literature corpus of about 39 000 articles in PubMed, with over 4300 new articles added in 2011. We have developed a literature curation workflow incorporating both automated and manual elements to cope with this flood of new research articles. The current workflow can be divided into two phases: article selection and curation. Structured controlled vocabularies, such as the Gene Ontology and Plant Ontology are used to capture free text information in the literature as succinct ontology-based annotations suitable for the application of computational analysis methods. We also describe our curation platform and the use of text mining tools in our workflow. Database URL: www.arabidopsis.org
A survey investigation of UK physiotherapists' use of online search engines for continuing professional development.	The purpose of this study was to discover the frequency and type of use of online resources for continuing professional development displayed by physiotherapists in the UK. Therapists' skills, needs and frustrations using these resources were explored. With the relatively recent release and saturated use of the internet the potential presence of a skills gap between therapists at different stages of their career was also investigated.
Assessment of the quality of web-based information on bunions.	The Internet provides a large source of health-related information for patients. However, information on the Internet is mostly unregulated, ranging from factually correct to misleading or contradictory information. The objective of this study was to determine the quality of information available on World Wide Web on the topic of bunions.
Use of a support vector machine for categorizing free-text notes: assessment of accuracy across two institutions.	Electronic health record (EHR) users must regularly review large amounts of data in order to make informed clinical decisions, and such review is time-consuming and often overwhelming. Technologies like automated summarization tools, EHR search engines and natural language processing have been shown to help clinicians manage this information.
Tools (Viewer, Library and Validator) that facilitate use of the peptide and protein identification standard format, termed mzIdentML.	The Proteomics Standards Initiative has recently released the mzIdentML data standard for representing peptide and protein identification results, for example, created by a search engine. When a new standard format is produced, it is important that software tools are available that make it straightforward for laboratory scientists to use it routinely and for bioinformaticians to embed support in their own tools. Here we report the release of several open-source Java-based software packages based on mzIdentML: ProteoIDViewer, mzidLibrary, and mzidValidator. The ProteoIDViewer is a desktop application allowing users to visualize mzIdentML-formatted results originating from any appropriate identification software; it supports visualization of all the features of the mzIdentML format. The mzidLibrary is a software library containing routines for importing data from external search engines, post-processing identification data (such as false discovery rate calculations), combining results from multiple search engines, performing protein inference, setting identification thresholds, and exporting results from mzIdentML to plain text files. The mzidValidator is able to process files and report warnings or errors if files are not correctly formatted or contain some semantic error. We anticipate that these developments will simplify adoption of the new standard in proteomics laboratories and the integration of mzIdentML into other software tools. All three tools are freely available in the public domain. 
Applications of social network media in medicolegal death investigation.	With the increased popularity of online social networking services (SNS) such as Facebook, LinkedIn, Twitter, and Google+, we propose that a wealth of new resources is available for medicolegal death investigation. Recognizing this potential, we identified cases in which social media had been useful in the past in our office and asked our investigative staff to consider using social media in current cases. These cases provided illustrative examples for this primer regarding how information from SNS was used in death investigations in our office. Information gleaned from online social media aided in establishing preliminary identification of a decedent, locating next-of-kin, investigating the circumstances of death as relevant to the manner of death, corroborating eyewitness accounts, and providing information relevant to time of death. Potential pitfalls were identified, such as shared accounts or online impostors. SNS proved useful to the medicolegal death investigator and medical examiner, so long as their limitations were recognized. 
A model for nurses seeking information using a scholarly information map.	Nurses are required to obtain highly sophisticated scholarly information to contribute to the health of medical consumers through evidence-based practice (EBP). However, it is often difficult to constantly find appropriate information resources and conduct searches to obtain desired and useful information. Therefore, a system that can be used to find reliable information to satisfy the needs of clinical nurses is required. This study aimed to support nurses seeking information to aid their practice. We propose a model to support the information seeking of nurses using 2 scholarly information maps: a "Resource Map" and an "Individual Map." The Resource Map contains comprehensive information of special fields for nurses. Meanwhile, the Individual Map contains elements of case reports that help nurses to accurately specify a patient's condition. This model can help nurses develop a habit of using these maps for advancements in nursing. 
Methods to detect replication-dependent and replication-independent DNA structure-induced genetic instability.	DNA can adopt a variety of alternative secondary (i.e., non-B DNA) conformations that play important roles in cellular metabolism, including genetic instability, disease etiology and evolution. While we still have much to learn, research in this field has expanded dramatically in the past decade. We have summarized in our previous Methods review (Wang et al., Methods, 2009) some commonly used techniques to determine non-B DNA structural conformations and non-B DNA-induced genetic instability in prokaryotes and eukaryotes. Since that time, we and others have further characterized mechanisms involved in DNA structure-induced mutagenesis and have proposed both replication-dependent and replication-independent models. Thus, in this review, we highlight some current methodologies to identify DNA replication-related and replication-independent mutations occurring at non-B DNA regions to allow for a better understanding of the mechanisms underlying DNA structure-induced genetic instability. We also describe a new web-based search engine to identify potential intramolecular triplex (H-DNA) and left-handed Z-DNA-forming motifs in entire genomes or at selected sequences of interest. 
Using Google blogs and discussions to recommend biomedical resources: a case study.	This case study investigated whether data gathered from discussions within the social media provide a reliable basis for a biomedical resources recommendation system. Using a search query to mine text from Google Blogs and Discussions, a ranking of biomedical resources was determined based on those most frequently mentioned. To establish quality, these results were compared with rankings by subject experts. An overall agreement between the frequency of social media discussions and subject expert recommendations was observed when identifying key bioinformatics and consumer health resources. Testing the method in more than one biomedical area implies this procedure could be employed across different subjects. 
Joanna Briggs Institute: an evidence-based practice database.	The Joanna Briggs Institute Evidence-Based Practice Database offers systematic reviews, practice recommendations, and consumer information designed to support evidence-based practice. A sample search was conducted within the Ovid platform to demonstrate functionality and available tools. 
Medical student views on the use of Facebook profile screening by residency admissions committees.	Previous research has shown that >50% of residency programmes indicate that inappropriate Facebook postings could be grounds for rejecting a student applicant. This study sought to understand medical students' views regarding the impact of their Facebook postings on the residency admissions process.
Characterizing the time-perspective of nations with search engine query data.	Vast quantities of data on human behavior are being created by our everyday internet usage. Building upon a recent study by Preis, Moat, Stanley, and Bishop (2012), we used search engine query data to construct measures of the time-perspective of nations, and tested these measures against per-capita gross domestic product (GDP). The results indicate that nations with higher per-capita GDP are more focused on the future and less on the past, and that when these nations do focus on the past, it is more likely to be the distant past. These results demonstrate the viability of using nation-level data to build psychological constructs.
BioTCM-SE: a semantic search engine for the information retrieval of modern biology and traditional Chinese medicine.	Understanding the functional mechanisms of the complex biological system as a whole is drawing more and more attention in global health care management. Traditional Chinese Medicine (TCM), essentially different from Western Medicine (WM), is gaining increasing attention due to its emphasis on individual wellness and natural herbal medicine, which satisfies the goal of integrative medicine. However, with the explosive growth of biomedical data on the Web, biomedical researchers are now confronted with the problem of large-scale data analysis and data query. Besides that, biomedical data also has a wide coverage which usually comes from multiple heterogeneous data sources and has different taxonomies, making it hard to integrate and query the big biomedical data. Embedded with domain knowledge from different disciplines all regarding human biological systems, the heterogeneous data repositories are implicitly connected by human expert knowledge. Traditional search engines cannot provide accurate and comprehensive search results for the semantically associated knowledge since they only support keywords-based searches. In this paper, we present BioTCM-SE, a semantic search engine for the information retrieval of modern biology and TCM, which provides biologists with a comprehensive and accurate associated knowledge query platform to greatly facilitate the implicit knowledge discovery between WM and TCM. 
