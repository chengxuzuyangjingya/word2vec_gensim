Superior ultra-audiometric hearing: a new type of hearing loss which correlates highly with unusually good speech in the "profoundly deaf".	This paper reports 42 severely-to-profoundly deaf subjects, 6 of whom have better hearing in the range of 8 to 14 kHz than below 8 kHz. Data on speech capabilities in these six subjects suggest that this ultra-audiometric range may contribute to their speech comprehension and control.
Tongue reconstruction with free radial forearm flap after hemiglossectomy: a functional assessment.	Thirty-three patients with squamous cell carcinoma of the anteriolateral part of the tongue underwent a 50 percent resection of the tongue. The surgical defect was reconstructed with a microvascular radial forearm flap. All the flaps were especially designed to have a narrow waist, shaped like an omega in cross-section, thus allowing for a free tongue tip, and avoiding suturing the edge of the flap to the soft palate and tongue base. Sixteen patients were evaluated for swallowing and speech function at least 6 months following reconstruction. With this technique, the majority of the patients had nearly normal deglutition, although their speech was still unsatisfactory. However, the speech function in this series was better than that in other reported series.
Comprehensive head and neck oncology health status assessment.	This article presents the validation of the Head and Neck Cancer Inventory (HNCI), a health status assessment instrument with a small number of multiple-item domains that captures patients' ratings of functional status and attitude about that function.
Somatosensory basis of speech production.	The hypothesis that speech goals are defined acoustically and maintained by auditory feedback is a central idea in speech production research. An alternative proposal is that speech production is organized in terms of control signals that subserve movements and associated vocal-tract configurations. Indeed, the capacity for intelligible speech by deaf speakers suggests that somatosensory inputs related to movement play a role in speech production-but studies that might have documented a somatosensory component have been equivocal. For example, mechanical perturbations that have altered somatosensory feedback have simultaneously altered acoustics. Hence, any adaptation observed under these conditions may have been a consequence of acoustic change. Here we show that somatosensory information on its own is fundamental to the achievement of speech movements. This demonstration involves a dissociation of somatosensory and auditory feedback during speech production. Over time, subjects correct for the effects of a complex mechanical load that alters jaw movements (and hence somatosensory feedback), but which has no measurable or perceptible effect on acoustic output. The findings indicate that the positions of speech articulators and associated somatosensory inputs constitute a goal of speech movements that is wholly separate from the sounds produced.
Using the Speech Transmission Index for predicting non-native speech intelligibility.	While the Speech Transmission Index (STI) is widely applied for prediction of speech intelligibility in room acoustics and telecommunication engineering, it is unclear how to interpret STI values when non-native talkers or listeners are involved. Based on subjectively measured psychometric functions for sentence intelligibility in noise, for populations of native and non-native communicators, a correction function for the interpretation of the STI is derived. This function is applied to determine the appropriate STI ranges with qualification labels ("bad"-"excellent"), for specific populations of non-natives. The correction function is derived by relating the non-native psychometric function to the native psychometric function by a single parameter (nu). For listeners, the nu parameter is found to be highly correlated with linguistic entropy. It is shown that the proposed correction function is also valid for conditions featuring bandwidth limiting and reverberation.
Intelligibility of bandpass filtered speech: steepness of slopes required to eliminate transition band contributions.	Despite the recognition that the steepness of filter slopes can play an important role in the intelligibility of bandpass speech, there has been no systematic examination of its importance. The present study used high orders of finite impulse response (FIR) filtering to produce slopes ranging from 150 to 10,000 dB/octave. The slopes flanked 1/3-octave passbands of everyday sentences having a center frequency of 1500 Hz (the region of highest intelligibility for the male speaker's voice). Presentation levels were approximately 75 and 45 dB. No significant differences were found for the two presentation levels. Average intelligibility scores ranged from 77% at 150 dB/octave down to the asymptotic intelligibility score of 12% at 4800 dB/octave. These results indicate that slopes of several thousand dB/octave may be required for accurate and unambiguous specification of the range of frequencies contributing to intelligibility of filtered speech. In addition, the extremely steep slopes are needed to ensure that none of the spectral components contributing to intelligibility has its relative importance diminished by spectral tilt.
Communication effectiveness of individuals with amyotrophic lateral sclerosis.	The purpose of this study was to examine the relationships among speech intelligibility and communication effectiveness as rated by speakers and their listeners. Participants completed procedures to measure (a) speech intelligibility, (b) self-perceptions of communication effectiveness, and (c) listener (spouse or family member) perceptions of communication effectiveness for speakers with amyotrophic lateral sclerosis (ALS). The results of this study revealed that perceptions of communication effectiveness for speakers with ALS were quite similar for the speakers and their frequent listeners across 10 different social situations. ALS speakers and their listeners reported a range of communication effectiveness depending upon the adversity of specific social situations.
Intelligibility of speech produced during simultaneous communication.	This study investigated the overall intelligibility of speech produced during simultaneous communication (SC). Four hearing, experienced sign language users were recorded under SC and speech alone (SA) conditions speaking Boothroyd's (1985) forced-choice phonetic contrast material designed for measurement of speech intelligibility. Twelve hearing-impaired listeners participated, with three of them randomly assigned to audit the speech sample provided by each one of the four speakers under the SC and SA conditions. Although results indicated longer sentence durations for SC than SA, results showed no difference in the overall intelligibility of speech produced during SC versus speech produced during SA, nor any difference in pattern of phonetic contrast recognition errors during SC. This conclusion is consistent with previous research indicating that temporal alterations produced by SC do not produce degradation of temporal or spectral cues in speech or disruption of the perception of specific English phoneme segments.
Age and laryngeal airway resistance during vowel production in women.	An investigation was conducted to determine if laryngeal valving economy, as reflected in measures of laryngeal airway resistance during vowel production, differs with age in women. Seventy healthy women were studied, 10 each at age 25, 35, 45, 55, 65, 75, and 85 years. Results indicated that laryngeal airway resistance did not differ significantly with age, although it was noted that the 45-year-old women generally had lower laryngeal airway resistance values. This pattern of function differs from that observed in men (Melcon, Hoit, & Hixon, 1989). Discussion of findings includes consideration of factors that might influence laryngeal function during speech production in women. Clinical implications are offered.
Application of an implantable bone conduction hearing device to patients with unilateral sensorineural hearing loss.	This investigation, comprised of five studies, was undertaken to determine if individuals with newly acquired profound unilateral hearing losses would benefit from an implantable bone-conduction hearing device. The bone conductor was implanted on the side of the deaf ear at the time of translabyrinthine acoustic tumor resection. Two areas greatly affected by unilateral hearing loss, speech recognition in noise and sound localization, were examined. No improvement in aided performance could be documented in either area.
Effect of glossopexy on speech sound production in Robin sequence.	The management of Robin sequence may include glossopexy, in which the tongue is attached to the lower lip and mandible for anterior lingual positioning to resolve upper airway obstruction. The procedure is performed early in infancy and reversed at the time of palatal repair near 1 year of age. This period is critical to prespeech vocalization. The effect of glossopexy on speech sound production was investigated in 17 children with Robin sequence who had glossopexies. Analysis suggested that glossopexy may temporarily affect the development of prespeech skills and sound production. The onset of babbling and initiation of first words was often delayed in the subjects in comparison with syndrome-matched children who had not undergone glossopexy. Tongue-tip sounds were often produced with the tongue blade, but production was perceptually normal. The early delays were temporary and the only long-term effect of glossopexy was a tendency to produce tongue-tip sounds with the tongue blade.
Speech intelligibility and childhood verbal apraxia in children with Down syndrome.	Many children with Down syndrome have difficulty with speech intelligibility. The present study used a parent survey to learn more about a specific factor that affects speech intelligibility, i.e. childhood verbal apraxia. One of the factors that affects speech intelligibility for children with Down syndrome is difficulty with voluntarily programming, combining, organising, and sequencing the movements necessary for speech. Historically, this difficulty, childhood verbal apraxia, has not been identified or treated in children with Down syndrome but recent research has documented that symptoms of childhood verbal apraxia can be found in children with Down syndrome. The survey examined whether and to what extent childhood verbal apraxia is currently being identified and treated in children with Down syndrome. The survey then asked parents to identify certain speech characteristics that occur always, frequently, sometimes or never in their child's everyday speech. There were 1620 surveys received. Survey results indicated that approximately 15% of the parents responding to the survey had been told that their child has childhood verbal apraxia. Examination of the everyday speech characteristics identified by the parents indicated that many more children are showing clinical symptoms of childhood verbal apraxia although they have not been given that diagnosis. The most common characteristics displayed by the subjects included decreased intelligibility with increased length of utterance, inconsistency of speech errors, difficulty sequencing oral movements and sounds, and a pattern of receptive language superior to expressive language. The survey also examined the impact of childhood verbal apraxia on speech intelligibility. Results indicated that children with Down syndrome who have clinical symptoms of childhood verbal apraxia have more difficulty with speech intelligibility, i.e. there was a significant correlation between childhood verbal apraxia and parental intelligibility ratings. Children with apraxia often do not begin to speak until after age 5. There was a significant correlation between speech intelligibility and age at which the child began to speak, i.e. children who began to speak after age 5 had lower parental intelligibility ratings. A diagnosis of difficulty with oral motor skills is more frequently given than a diagnosis of apraxia; 60.2% of parents had been given this diagnosis. According to survey results, it is rare (2%) for a diagnosis of childhood verbal apraxia to be made without a diagnosis of difficulty with oral motor skills.
BAHA in children and adolescents with unilateral or bilateral conductive hearing loss: a study of outcome.	Bilateral BAHAs in adults with bilateral hearing loss (BHL) have proven to be superior to unilateral fitting, in both audiologically measurements and in overall patient satisfaction. There have been no similar studies in children. Furthermore, a recent meta-analysis of children with unilateral hearing loss (UHL) has shown numerous negative consequences. The objectives of the study were to investigate whether fitting of bilateral BAHAs in children with conductive BHL give additional hearing benefits, to investigate the effects of unilateral hearing aids in children with conductive UHL, and to identify different aspects of auditory problems in children with conductive UHL or BHL.
Temporal jitter disrupts speech intelligibility: a simulation of auditory aging.	We disrupted periodicity cues by temporally jittering the speech signal to explore how such distortion might affect word identification. Jittering distorts the fine structure of the speech signal with negligible alteration of either its long-term spectral or amplitude envelope characteristics. In Experiment 1, word identification in noise was significantly reduced in young, normal-hearing adults when sentences were temporally jittered at frequencies below 1.2kHz. The accuracy of the younger adults in identifying jittered speech in noise was similar to that found previously for older adults with good audiograms when they listened to intact speech in noise. In Experiment 2, to rule out the possibility that the reductions in word identification were due to spectral distortion, we also tested a simulation of cochlear hearing loss that produced spectral distortion equivalent to that produced by jittering, but this simulation had significantly less temporal distortion than was produced by jittering. There was no significant reduction in the accuracy of word identification when only the frequency region below 1.2kHz was spectrally distorted. Hence, it is the temporal distortion rather than the spectral distortion of the low-frequency components that disrupts word identification.
Effects of loudness cues on respiration in individuals with Parkinson's disease.	Individuals with Parkinson's disease (PD) demonstrate low vocal intensity (hypophonia) which results in reduced speech intelligibility. We examined the effects of three cues to increase loudness on respiratory support in individuals with PD. Kinematic data from the rib cage and abdomen were collected using respiratory plethysmography while participants read a short passage. Individuals with PD and normal age- and sex-matched controls (OC) increased sound pressure level (SPL) to a similar extent. As compared to OC, individuals with PD used larger rib cage volume excursions in all conditions. Further, they did not slow their rate of speech in noise as OC speakers did. Respiratory strategies used to support increased loudness varied with the cue, but the two groups did not differ in the strategies used. When asked to target a specific loudness, both groups used more abdominal effort than at comfortable loudness. Speaking in background noise resulted in the largest increase in SPL with the most efficient respiratory patterns, suggesting that natural or implicit cues may be best when treating hypophonia in individuals with PD. Data demonstrate the possibility that both vocal loudness and speech rate are impacted by cognitive mechanisms (attention or self-perception) in individuals with PD.
Cleft palate speech and velopharyngeal insufficiency: surgical approach.	Velopharyngeal insufficiency is the main morbidity associated with clefting of the secondary palate. Therefore, it is important to monitor speech production in all children with a history of cleft palate. Diagnosis and management of velopharyngeal insufficiency is an important function of the cleft palate team. The surgical approach used in the Craniofacial Center at Children's Hospital and Regional Medical Center, Seattle, Washington, USA is presented. Assessment of velopharyngeal function, as it relates to surgical intervention and measurement of outcome, is reviewed. Surgical management using Furlow palatoplasty and sphincter pharyngoplasty is discussed.
Tone production of Mandarin Chinese speaking children with cochlear implants.	The purpose of the present study was to investigate tone production performance of native Mandarin Chinese speaking children with cochlear implants and to evaluate the effects of age at implantation and duration of implant use on tone production in those children.
Development of the Cantonese speech intelligibility index.	A Speech Intelligibility Index (SII) for the sentences in the Cantonese version of the Hearing In Noise Test (CHINT) was derived using conventional procedures described previously in studies such as Studebaker and Sherbecoe [J. Speech Hear. Res. 34, 427-438 (1991)]. Two studies were conducted to determine the signal-to-noise ratios and high- and low-pass filtering conditions that should be used and to measure speech intelligibility in these conditions. Normal hearing subjects listened to the sentences presented in speech-spectrum shaped noise. Compared to other English speech assessment materials such as the English Hearing In Noise Test [Nilsson et al., J. Acoust. Soc. Am. 95, 1085-1099 (1994)], the frequency importance function of the CHINT suggests that low-frequency information is more important for Cantonese speech understanding. The difference in ,frequency importance weight in Chinese, compared to English, was attributed to the redundancy of test material, tonal nature of the Cantonese language, or a combination of these factors.
Free anterolateral thigh flap versus free forearm flap: Functional results in oral reconstruction.	Nowadays, microsurgery performed for oral reconstruction of cancer patients, has become the standard treatment in restoring oral functions. The free radial forearm flap (FRFF) is still apparently the first reconstructive choice in oral cavity cancers. Recently the anterolateral thigh flap (ALTF) seemed to challenge the superiority of FRFF. The lack of functional data on which to base this recent supposition is the reason for this new research. Twenty reconstructed patients were enrolled for this study. Speech, swallowing, and donor site complications were studied to assess differences between the two techniques. Results show that difference in function between ALTF and FRFF groups is statistically insignificant. Donor site risks and complications seem to be the only variables among groups. These variables may be used as indicators when making a surgical choice.
Spontaneous otoacoustic emission enhancement in children with reduced speech-in-noise intelligibility.	Reduced speech-in-noise intelligibility is one of the main difficulties experienced by children with auditory processing disorder (APD). Previous studies have established a relationship between the function of the medial olivocochlear system (MOCS) and reduced inhibition of otoacoustic emissions (OAE) in children with APD. This study measured spontaneous OAE (SOAE) in 27 children with reduced speech-in-noise intelligibility, and those of a control group matched by gender and age. A significantly higher prevalence of SOAE was found: 85% of the study group presented SOAE, 44% in the control group. An abnormally functioning MOCS with reduced inhibition could lead to an increase in SOAE. Identifying a higher prevalence and number of SOAE may be a helpful objective mean to include in an APD diagnosis test battery.
Speech pattern improvement following gingivectomy of excess palatal tissue.	Speech disruption secondary to excessive gingival tissue has received scant attention in periodontal literature. Although a few articles have addressed the causes of this condition, documentation and scientific explanation of treatment outcomes are virtually non-existent. This case report describes speech pattern improvements secondary to periodontal surgery and provides a concise review of linguistic and phonetic literature pertinent to the case.
Intelligibility measurements in speech disorders: a critical review of the literature.	the reduction in speech intelligibility is considered one of the main characteristics of individuals with speech disorders, and is an important issue for clinical and research investigation. In spite of its relevance, the literature does not present a consensus on how to measure speech intelligibility. Besides the diversity of existent methods, another important issue refers to the influence of certain variables on these measurements and, consequently, on the interpretation of the results.
Effects of speaking task on intelligibility in Parkinson's disease.	Intelligibility tests for dysarthria typically provide an estimate of overall severity for speech materials elicited through imitation or read from a printed script. The extent to which these types of tasks and procedures reflect intelligibility for extemporaneous speech is not well understood. The purpose of this study was to compare intelligibility estimates obtained for a reading passage and an extemporaneous monologue produced by 12 speakers with Parkinson's disease (PD). The relationship between structural characteristics of utterances and scaled intelligibility was explored within speakers. Speakers were audio-recorded while reading a paragraph and producing a monologue. Speech samples were separated into individual utterances for presentation to 70 listeners who judged intelligibility using orthographic transcription and direct magnitude estimation (DME). Results suggest that scaled estimates of intelligibility for reading show potential for indexing intelligibility of an extemporaneous monologue. Within-speaker variation in scaled intelligibility also was related to the number of words per speech run for extemporaneous speech.
Automatic quantification of speech intelligibility in patients after treatment for oral squamous cell carcinoma.	Treatment of oral carcinomas often causes reduced speech intelligibility. It was the aim of this study to objectively evaluate the speech intelligibility of patients after multimodal therapy for oral squamous cell carcinoma (OSCC) with a computer-based, automatic speech recognition system.
Assessment of quality of life after implant-retained prosthetically reconstructed maxillae and mandibles postcancer treatments.	The aim of this prospective study was to assess treatment outcome and impact on quality of life with implant-retained prosthesis in reconstructed jaws in head and neck cancer patients.
Prevalence of GJB2-associated deafness and outcomes of cochlear implantation in Iran.	To investigate the prevalence of mutations in the coding exon of the GJB2 gene in Iranian children with cochlear implants, and to compare the outcomes of auditory perception and speech production in cochlear-implanted children with and without GJB2 mutation.
Effects of white noise on Callsign Acquisition Test and Modified Rhyme Test scores.	The Callsign Acquisition Test (CAT) is a speech intelligibility test developed by the US Army Research Laboratory. The test has been used to evaluate speech transmission through various communication systems but has not been yet sufficiently standardised and validated. The aim of this study was to compare CAT and Modified Rhyme Test (MRT) performance in the presence of white noise across a range of signal-to-noise ratios (SNRs). A group of 16 normal-hearing listeners participated in the study. The speech items were presented at 65 dB(A) in the background of white noise at SNRs of -18, -15, -12, -9 and -6 dB. The results showed a strong positive association (75.14%) between the two tests, but significant differences between the CAT and MRT absolute scores in the range of investigated SNRs. Based on the data, a function to predict CAT scores based on existing MRT scores and vice versa was formulated. STATEMENT OF RELEVANCE: This work compares performance data of a common speech intelligibility test (MRT) with a new test (CAT) in the presence of white noise. The results here can be used as a part of the standardisation procedures and provide insights to the predictive capabilities of the CAT to quantify speech intelligibility communication in high-noise military environments.
Cochlear dead regions in typical hearing aid candidates: prevalence and implications for use of high-frequency speech cues.	This study had two purposes. The first was to assess the prevalence of cochlear dead regions (DRs) among listeners with moderate to severe hearing loss that is typical of a large proportion of adult hearing aid wearers. The second was to determine whether subjects who tested positive for DRs differed from those without DRs in their ability to utilize high-frequency speech cues in a laboratory test.
Influence of tinnitus sound therapy signals on the intelligibility of speech.	To assess the influence on speech intelligibility of various signals used in tinnitus sound therapy.
Effects of a denture adhesive in edentulous patients after maxillectomy.	The objective of this study is to evaluate the usefulness of a denture adhesive in edentulous patients after maxillectomy.
Syntactic development in Japanese hearing-impaired children.	This study examined syntactic development of auditory comprehension of sentences in Japanese-speaking school-age children with and without hearing impairment.
Relationship between listening difficulty rating and objective measures in reverberant and noisy sound fields for young adults and elderly persons.	Listening difficulty ratings [Morimoto et al., J. Acoust. Soc. Am. 116, 1607-1613 (2004)] were obtained for 20 young adult listeners and 34 elderly listeners in reverberant and noisy sound fields simulated in an anechoic room. The listening difficulty ratings were compared with acoustical objective measures. The results and analyses showed the following: (i) The correlation between listening difficulty ratings and the revised speech transmission index (STI(r)), and that for the useful-detrimental ratio (U(50)) were high, regardless of the age of the listeners. (ii) STI(r) and U(50) need to be increased by 0.12 and 4.2 dB, respectively, to equalize the listening difficulty ratings for the elderly listeners with those for the young listeners. (iii) The estimation accuracies for STI(r) and U(50) can be improved by calculating them with the L(eq) of background noise linearly increased by 4 to 10 dB, which depends on the age of the listeners and the objective measures. However, the improvement was not statistically significant for the elderly listeners.
Speech intelligibility improvements with hearing aids using bilateral and binaural adaptive multichannel Wiener filtering based noise reduction.	This paper evaluates noise reduction techniques in bilateral and binaural hearing aids. Adaptive implementations (on a real-time test platform) of the bilateral and binaural speech distortion weighted multichannel Wiener filter (SDW-MWF) and a competing bilateral fixed beamformer are evaluated. As the SDW-MWF relies on a voice activity detector (VAD), a realistic binaural VAD is also included. The test subjects (both normal hearing subjects and hearing aid users) are tested by an adaptive speech reception threshold (SRT) test in different spatial scenarios, including a realistic cafeteria scenario with nonstationary noise. The main conclusions are: (a) The binaural SDW-MWF can further improve the SRT (up to 2 dB) over the improvements achieved by bilateral algorithms, although a significant difference is only achievable if the binaural SDW-MWF uses a perfect VAD. However, in the cafeteria scenario only the binaural SDW-MWF achieves a significant SRT improvement (2.6 dB with perfect VAD, 2.2 dB with real VAD), for the group of hearing aid users. (b) There is no significant degradation when using a real VAD at the input signal-to-noise ratio (SNR) levels where the hearing aid users reach their SRT. (c) The bilateral SDW-MWF achieves no SRT improvements compared to the bilateral fixed beamformer.
Characteristics of hearing aid fittings in infants and young children.	Hearing aids (HAs) provide the basis for improving audibility and minimizing developmental delays in children with mild to severe hearing loss. Multiple guidelines exist to recommend methods for optimizing amplification in children, but few previous studies have reported HA fitting outcomes for a large group of children. The present study sought to evaluate the proximity of the fitting to prescriptive targets and aided audibility of speech, as well as survey data from pediatric audiologists who provided HAs for the children in the present study. Deviations from prescriptive target were predicted to have a negative impact on aided audibility. In addition, children who were fitted using verification with probe microphone measurements were expected to have smaller deviations from prescriptive targets and greater audibility than cohorts fitted without these measures.
Quality of life after management of advanced osteoradionecrosis of the mandible.	Osteoradionecrosis (ORN) of the mandible is a severe complication of radiation therapy for head and neck cancer. In this case series, the authors analyzed their treatment and quality of life outcomes over the past 6 years. A retrospective chart review of 42 patients treated surgically for advanced ORN was conducted. A telephone survey was conducted and quality of life (QOL) questionnaires were completed in a subset of patients. 30 patients responded to the telephone survey assessing QOL for speech, swallowing and overall functioning correlated with oral nutrition and performance status. Surgery for ORN can result in an improved QOL. Functional outcomes of oral intake, speech intelligibility, and eating in public correlated with patient rated QOL measures. A lack of improvement in QOL, despite the restoration of an intact mandible, relates to the persistent effects of chemoradiotherapy. 
Effect of maxillary osteotomy on speech in cleft lip and palate: perceptual outcomes of velopharyngeal function.	Abnormal facial growth is a well-known sequelae of cleft lip and palate (CLP) resulting in maxillary retrusion and a class III malocclusion. In 10-50% of cases, surgical correction involving advancement of the maxilla typically by osteotomy methods is required and normally undertaken in adolescence when facial growth is complete. Current evidence for the impact of the surgery on velopharyngeal function is weak and mixed.
Auditory-motor interactions in pediatric motor speech disorders: neurocomputational modeling of disordered development.	Differentiating the symptom complex due to phonological-level disorders, speech delay and pediatric motor speech disorders is a controversial issue in the field of pediatric speech and language pathology. The present study investigated the developmental interaction between neurological deficits in auditory and motor processes using computational modeling with the DIVA model.
Evaluation of the sparse coding shrinkage noise reduction algorithm in normal hearing and hearing impaired listeners.	Although there are numerous single-channel noise reduction strategies to improve speech perception in noise, most of them improve speech quality but do not improve speech intelligibility, in circumstances where the noise and speech have similar frequency spectra. Current exceptions that may improve speech intelligibility are those that require a priori knowledge of the speech or noise statistics, which limits practical application. Hearing impaired (HI) listeners suffer more in speech intelligibility than normal hearing listeners (NH) in the same noisy environment, so developing better single-channel noise reduction algorithms for HI listeners is justified. Our model-based "sparse coding shrinkage" (SCS) algorithm extracts key speech information in noisy speech. We evaluate it by comparison with a state-of-the-art Wiener filtering approach using speech intelligibility tests with NH and HI listeners. The model-based SCS algorithm relies only on statistical signal information without prior information. Results show that the SCS algorithm improves speech intelligibility in stationary noise and is comparable to the Wiener filtering algorithm. Both algorithms improve intelligibility for HI listeners but not for NH listeners. Improvement is less in fluctuating (babble) noise than in stationary noise. Both noise reduction algorithms perform better at higher input signal-to-noise ratios (SNR) where HI listeners can benefit but where NH listeners have already reached ceiling performance. The difference between NH and HI subjects in intelligibility gain depends fundamentally on the input SNR rather than the hearing loss level. We conclude that HI listeners need different signal processing algorithms from NH subjects and that the SCS algorithm offers a promising alternative to Wiener filtering. Performance of all noise reduction algorithms is likely to vary according to extent of hearing loss and algorithms that show little benefit for listeners with moderate hearing loss may be more beneficial for listeners with more severe hearing loss. 
The influence of attack time and release time on speech intelligibility. A study of the effects of AGC on normal hearing and hearing impaired subjects.	Automatic gain control may be used in hearing aids intended for different types and degrees of hearing loss; to average the levels, to reduce the dynamics of speech or to set the maximum output level of the hearing aid without adding nonlinear distortion. Our study concerns hearing impaired listeners with recruitment. A group of normal hearing subjects was used as a control group. The compression was introduced over a laboratory unit. The compression ratio was set to 30:5 dB. A fixed ratio between the attack time and the release time, tr = 200 x ta, was used. The values used varied from 0.05 to 5 ms for ta and 10 - 1000 ms for tr. The speech material was nonsense syllables of the CVC type presented with S/N = 60 dB and S/N = 5 dB. With S/N = 5 dB a significant deterioration of the discrimination of the nonsense syllables was found at time constant combination ta = 5 ms and tr = 1000 ms. No statistically significant difference in discrimination was found between the different combinations of attack and release times for the S/N = 60 dB condition neither for the normal hearing nor for the hearing impaired group.
Speech intelligibility in noise: effects of fluency and hearing protector type.	This research investigated the effect of car protectors on the intelligibility of speech in noise. Listeners with normal hearing, high-frequency, and flat loss were tested. Half the subjects in each group were fluent in English and half-poorly conversant. Taped lists of 25 words were presented free field under conditions defined by the speech-to-noise ratio, spectrum of noise background, and presence of ear protection. The results showed that intelligibility decreased with speech-to-noise ratio and was poorer in crowd noise than in white noise. The protector had no effect for the normal listener, but caused a substantial decrement in those with impairment. In all groups nonfluency contributed an additional loss of 10% to 20%. Significant differences in performance were noted for different muff and plug types.
Increasing the intelligibility of sung vowels.	The intelligibility of the front vowels (/i/, /I/, /epsilon/, and /ae/) was investigated as sung in four different ways: (1) operatic, (2) in consonant-vowel-consonant (CVC) context, (3) with a raised larynx, and (4) with both raised larynx and in CVC context. Al syllables were sung by a trained soprano at F4, A4, C sharp 5, F5, A5, and C sharp 6. Ten subjects listened and identified randomized sets of ten tokens of each vowel per condition (method of articulation) at each note. Results showed that, from C sharp 5 (nominal 554 Hz) to F5 (698 Hz), the intelligibility of operatic vowels (condition 1) fell from 56% to 16%. The mean intelligibility of the vowels at the three highest notes (F5, A5, C sharp 6) was 10% for condition 1, 64% for condition 2, 62% for condition 3, and 83% for condition 4. Results indicate that increased intelligibility across conditions is a function of increased energy in the higher harmonics and presence of consonantal transitions. The generally accepted notion that vowel sounds are largely unintelligible on higher notes pertains only to a restricted manner of production.
A study on speech intelligibility in traffic noise]	In studying speech intelligibility in traffic noise, I was able to reproduce a sound field with considerable reality by reproducing both speech and traffic noises by the speaker method using a CD. As a result, the following conclusions were reached. 1) The influence of noise on speech intelligibility is similar for the single syllable and adult disyllable in normal persons. 2) The influence of the kinds of noises and changes with time in the sound pressure level on the intelligibility of the single syllable does not easily manifest itself in patients with sensorineural hearing loss. 3) The speech intelligibility depends largely on the blocking effect of the mid-high frequency components of the noise in both normal persons and patients with sensorineural hearing loss. 4) The intelligibility of the second sound of the adult disyllable is good in both normal persons and patients with sensorineural hearing loss. Furthermore, normal persons can understand a significant disyllable word to some extent by means of "uncertain understanding" even when they cannot hear each vowel and consonant clearly. 5) The intelligibility of the vowel is good in both normal persons and patients with sensorineural hearing loss. 6) As for the intelligibility classified by consonant in normal persons, the intelligibility of the nasal sounds (m, n) and voiced consonants (b, d, g, r, z) becomes low in the case of the S/N ratio being poor. 7) In patients with sensorineural hearing loss, the intelligibility of the bulldozer noise was the lowest, followed by motorway noise among the noises applied. The frequency spectrum distribution of the former consisted mainly of mid-high frequencies of 1 kHz or more. A serrated change with an amplitude of about 6 dB, 2 Hz was noted at the sound pressure level. A sine wave-like change with an amplitude of about 7 dB, 1 Hz was recognized at the sound pressure level of the latter. These are considered to be factors which account for a decline in intelligibility. The present study is part of an experiment I conducted at a sound field using TY-89. The results of this experiment suggest that the frequency spectrum intelligibility of noise as well as time-dependent changes in the sound pressure level of the noise exert an influence on communication disruption in patients with sensorineural hearing loss.
Abnormal speech articulation, psychomotor retardation, and subcortical dysfunction in major depression.	Psychomotor retardation, characterized by changes in speech, motility and cognition, is common in major depression. It is also a cardinal feature of subcortical disorders such as Parkinson's disease (PD). Based on this observation and other data it has been hypothesized that the retardation of depression is related to mesolimbic-nigrostriatal dysfunction. To further test this hypothesis, speech articulation in major depression was compared to that in PD, where disordered articulation is related to bradykinesia and rigidity caused by striatal dopamine depletion. Thirty subjects with major depression were compared with 30 patients with PD and 31 normal controls on 3 acoustic measures of articulation. Major depression and PD groups had significantly shortened voice onset time and decreased second formant transition compared to controls, and major depression also had increased spirantization. There were no differences between the depression and PD groups on any of the acoustic measures. These findings provide indirect support for the hypothesis that nigrostriatal dysfunction is related to psychomotor slowing in major depression.
Early otitis media and phonological development at age 2 years.	The effect of early otitis media on phonology and articulation in the presence of expressive language delay was investigated in 16 2-year-olds followed prospectively from birth. Eight of the children were designated otitis-positive and 8 were considered otitis-negative as determined by bilateral pneumatic otoscopy outcomes during year 1 of life. The groups differed significantly on measures of expressive, not receptive, language development. All members of the otitis-positive group were expressive language delayed. Phonological analyses were completed on spoken language samples elicited from each child at age 24 months. Results showed similar developmental tendencies in speech sound acquisition between the groups, but the otitis-positive group had established significantly fewer initial consonant phones and produced them less accurately than the otitis-negative subject group. The otitis-positive group acquired significantly fewer consonants with back place of articulation. Similar phonological error patterns of deletion and phoneme class deficiency were used by the groups, but the otitis-positive group used the error patterns more frequently. Findings here lend support to the otitis media effect as one of interaction among risk factors.
Cleft palate speech dissected: a review of current knowledge and analysis.	In this review, normal speech and its development is described and compared with the patterns typical of cleft palate speech. Attention is drawn to the importance of measuring and analysing these factors adequately for research and audit purposes, and the need for agreed parameters for reporting outcomes.
